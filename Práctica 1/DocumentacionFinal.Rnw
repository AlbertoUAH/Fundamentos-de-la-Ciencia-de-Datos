\documentclass [a4paper] {article}
\usepackage[hidelinks]{hyperref}
\usepackage[spanish,activeacute]{babel}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{graphicx}

\graphicspath{ {./imagenes/} }

\title{\textbf{Fundamentos de la Ciencia de Datos Práctica 1}}
\author{
	Fernández Díaz, Daniel.\\
	Cano Díaz, Francisco.\\
	Fernández Hernández, Alberto.\\
}

\date{15 de octubre del 2019}
\begin{document}
\maketitle

\section{Apartado 1}

Análisis estadístico de descripción de Datos en R. Para realizar este análisis utilizaremos dos ficheros de datos:
\begin{enumerate}
	\item \textbf{Fichero \textit{.txt}} con los datos de los satélites menores de Urano: nombre del satélite y su radio en km.
	\item \textbf{Fichero \textit{.sav}} (SPSS) formado por datos de automóviles, tales como su consumo en mpg (millas por galón), cilindrada, aceleración, año de fabricación, modelo etc.
\end{enumerate}

\subsection{Fichero \textit{.txt}}
Para comenzar a leer ficheros \textit{.txt} deberemos seguir una serie de reglas para generar el formato correcto:
\begin{itemize}
	\item Debe haber una tabulación entre dato y dato.
	\item Debe haber una primera columna que enumere las filas excepto la primera fila que tendrá un espacio en blanco. Además, en la primera fila irá el nombre de las variables.
	\item Hay que introducir un \textit{enter} al final de la última fila.
	\item Los decimales se introducen con punto.
	\item En las variables tipo caracter no se puede dejar un espacio entre caracteres.
\end{itemize}

\newpage

\begin{figure}
Siguiendo estas reglas generaremos un fichero con los datos de los satélites menores de Urano:

\centering
\includegraphics[width=3cm]{figura1}
\caption{Fichero \textit{.txt}.}
\end{figure}

Una vez creado el fichero nos disponemos a leer los datos que contiene. Para ello utilizaremos el comando \textbf{\textit{read.table}}:
<<>>=
satelites <- read.table("satelites.txt")
satelites
@

Para llevar a cabo el análisis de los datos anteriores calcularemos las siguientes magnitudes:
\subsubsection{Frecuencia Absoluta y Acumulada}
Para calcular la frecuencia absoluta utilizaremos el comando \textbf{\textit{table}}:
<<>>=
frecabsradio <- table(satelites$radio)
frecabsradio
@
\newpage
Por otro lado, para calcular la frecuencia absoluta acumulada utilizaremos la frecuencia absoluta anterior y, con el comando \textbf{\textit{cumsum}}, realizaremos la suma acumulativa de las frecuencias absolutas:
<<>>=
frecabsacmradio <- cumsum(frecabsradio)
frecabsacmradio
@

\subsubsection{Frecuencia Relativa y Acumulada}
Para calcular la frecuencia relativa crearemos la siguiente función a través del comando \textbf{\textit{function}}. Esta función dividirá la frecuencia absoluta de cada dato entre el número total de datos:
<<>>=
frecrel <- function(x) {table(x)/length(x)}
@

Una vez creada la función la guardamos en un fichero \textit{.R} a través del comando \textbf{\textit{dump}}, lo que nos permitirá cargarla en cualquier script que hagamos:
<<>>=
dump("frecrel",file = "frecrel.R")
@

Para cargar scripts en \textit{.R} y poder utilizar sus funciones utilizaremos el comando \textbf{\textit{source}}:
<<>>=
source("frecrel.R")
@

Una vez cargado calcularemos la frecuencia relativa:
<<>>=
frecrelradio <- frecrel(satelites$radio)
#Lo convertimos a dataframe para mostrarlo por pantalla de una forma más limpia
df = data.frame(frecrelradio)
print(df, row.names = FALSE)
@
\newpage
Por otro lado, para calcular la frecuencia relativa acumulada utilizaremos la frecuencia relativa anterior y con el comando \textbf{\textit{cumsum}} realizaremos la suma acumulativa de las frecuencias relativas:
<<>>=
frecrelacmradio <- cumsum(frecrelradio)
#Lo convertimos a dataframe para mostrarlo por pantalla de una forma más limpia
df = data.frame(frecrelacmradio)
print(df)
@

\subsubsection{Media Aritmética}
Para calcular la media aritmética utilizaremos el comando \textbf{\textit{mean}}:
<<>>=
mr <- mean(satelites$radio)
mr
@

\subsubsection{Desviación Típica}
Para calcular la desviación típica utilizaremos el comando \textbf{\textit{sd}}:
<<>>=
sdr <- sd(satelites$radio)
sdr
@

El problema de esta función \textbf{\textit{sd}} es que está pensada para poblaciones haciendo uso de la siguiente fórmula matemática:\newline
\begin{equation}
	\sqrt{\frac{\sum_{i=1}^n (x_i-\overline{x})^2}{n-1}}
\end{equation}
Mientras que la fórmula de la desviación para muestras es la siguiente:\newline

\begin{equation}
	\sqrt{\frac{\sum_{i=1}^n (x_i-\overline{x})^2}{n}}
\end{equation}
\newpage
Si nos fijamos la única diferencia la tenemos en el denominador por lo que debemos realizar la siguiente modificación para calcular la desviación típica para muestras:
<<>>=
#Elevando al cuadrado la desviación típica, quitamos la raíz,
#multiplicamos por n/n-1 (n = numero de elementos) y, a continuacion,
#creamos de nuevo la raiz cuadrada
sdr <- sqrt((sdr^2)*(11/12))
sdr
@

\subsubsection{Varianza}
Para calcular la varianza utilizaremos el comando \textbf{\textit{var}}. Como la varianza es el cuadrado de la desviación debemos realizar la misma modificación que antes para calcular la varianza sobre muestras y no sobre población:
<<>>=
varr <- var(satelites$radio)
varr <- varr*(11/12)
varr
@

\subsubsection{Mediana}
Para calcular la mediana utilizaremos el comando \textbf{\textit{median}}:
<<>>=
medianr <- median(satelites$radio)
medianr
@

\subsubsection{Cuantiles}
Para calcular los cuantiles utilizaremos el comando \textbf{\textit{quantile}}:
<<>>=
#Cuartil 1: 1/4
cuar1 <- quantile(satelites$radio,0.25)
cuar1
#Cuartil 2: 2/4 (coincide con la mediana)
cuar2 <- quantile(satelites$radio,0.50)
cuar2
#Cuartil 3: 3/4
cuar3 <- quantile(satelites$radio,0.75)
cuar3
#Cuantil 54
cuar54 <- quantile(satelites$radio,0.54)
cuar54
@

\subsection{Fichero .sav (SPSS)}
Para comenzar a leer ficheros \textit{.sav} deberemos cargar el paquete \textit{foreign}:
<<>>=
library(foreign)
#Vemos los paquetes cargados
#Lo convertimos a dataframe para mostrarlo por pantalla de una forma más limpia
df <- data.frame(search())
df
@

Una vez cargado el paquete nos disponemos a cargar el fichero \textit{.sav} con el comando \textbf{\textit{read.spss}}:
<<>>=
cardata <- read.spss("cardata.sav")
@

A partir de hora trabajaremos con la variable mpg para realizar el análisis:
<<>>=
#Veamos los datos de mpg
mpg <- cardata$mpg
#Lo convertimos a dataframe para mostrarlo por pantalla de una forma más limpia
#Mostraremos solo del dato 100 al 110
df <- data.frame(mpg)
df <- df[100:110,]
df
@
\newpage
Como podemos observar, tenemos valores a NA por lo que deberemos quitarlos (por el momento) para realizar el análisis:
<<>>=
mpg <- mpg[!is.na(mpg)]
#Lo convertimos a dataframe para mostrarlo por pantalla de una forma más limpia
#Mostraremos solo del dato 100 al 110 para verificar que ha quitado los NA
df <- data.frame(mpg)
df <- df[100:110,]
df
@

Una vez tenemos los datos listos nos disponemos a realizar el análisis a través del cálculo de las siguientes magnitudes:
\subsubsection{Media Aritmética}
<<>>=
mmpg <- mean(mpg)
mmpg
@

\subsubsection{Desviación Típica}
<<>>=
sdr <- sd(mpg)
sdr <- sqrt((sdr^2)*((length(mpg)-1)/length(mpg)))
sdr
@

\subsubsection{Varianza}
<<>>=
varr <- var(mpg)
varr <- varr*((length(mpg)-1)/length(mpg))
varr
@

\subsubsection{Mediana}
<<>>=
medianr <- median(mpg)
medianr
@

\subsubsection{Cuartiles}
<<>>=
cuar1 <- quantile(mpg,0.25)
cuar1
cuar2 <- quantile(mpg,0.50)
cuar2
cuar3 <- quantile(mpg,0.75)
cuar3
@

\section{Apartado 2}
Análisis estadístico de descripción de Datos en R usando nuevos formatos de fichero, así como nuevas funciones y librerías.
Para ello se han utilizado los siguientes archivos:

\begin{itemize}
	\item Fichero \textbf{.txt} con los datos de los satélites de Urano: nombre del satélite y su radio en km.
	\item Fichero \textbf{.csv} con los datos de los satélites anteriores (ver anexo para lectura de ficheros en .csv).
	\item Fichero \textbf{.sav} (SPSS) formado por datos de automóviles, tales como su consumo en mpg (millas por galón), cilindrada, aceleración, año de fabricación, modelo etc.
	\item Fichero \textbf{.json} con los datos de contaminación registrados en el año 2019 en la ciudad de Alcobendas. \footnote{\url{https://datos.gob.es/es/catalogo/l01280066-contaminacion-atmosferica-por-horas-ano-en-curso}}
	\item Fichero \textbf{.xslx} con la información de diferentes especies de plantas. \footnote{\url{https://www.kaggle.com/uciml/iris/download}}
\end{itemize}

Para la realización de la práctica se han utilizado los siguientes paquetes:
\begin{itemize}
	\item \textit{package(foreign)} \textbf{para la lectura de ficheros .sav}.
	\item \textit{package(rjson)} \textbf{para la lectura de ficheros .json}.
	\item \textit{package(XLConnect)} \textbf{para la lectura de ficheros Excel .xlsx}.
	\item \textit{package(dplyr)} \textbf{, el cual proporciona una gramática para la manipulacion de \textit{data frames}}.
\end{itemize}

Para la lectura de ficheros, utilizaremos una funcion denominada \textbf{leer.archivo} que se encargará de crear un \textit{dataframe} a partir del archivo indicado como parámetro. Por otro lado, la función proporcionará una
serie de argumentos adicionales en función del tipo de archivo.
\newpage
<<results=hide>>=
leer.archivo <- function(nombre, header = FALSE, sep = "", dec=".", skipNul=FALSE, 
to.data.frame=TRUE, sheet=1,startRow=1,endCol=2){}
@
\begin{enumerate}
	\item \textit{header(para ficheros .txt y .csv)}: indica si el archivo presenta o no cabecera. Por defecto está establecido a \textbf{FALSE}.
	\item \textit{sep(para ficheros .txt y .csv)}: indica el caracter separador, establecido a \textbf{cadena vacía} por defecto.
	\item \textit{dec(para ficheros .txt y .csv)}: indica la separación de números decimales, por defecto a \textbf{'.'}
	\item \textit{skipNul(para ficheros .txt y .csv)}: indica si la carga debe saltarse valores a \textbf{NA}. Por defecto, está establecido a \textbf{FALSE}.
	\item \textit{to.data.frame(para ficheros .sav)}: si queremos que los datos estén almacenados en un \textit{data frame}, por lo que está establecido a \textbf{TRUE} por defecto.
	\item \textit{sheet(para ficheros .xlsx)}: indica el número de hoja que deseamos importar. Por defecto, la lectura de los datos se realiza sobre la primera hoja.
	\item \textit{startRow(para ficheros .xlsx)}: indica la fila de inicio (\textbf{1}, por defecto).
	\item \textit{endCol(para ficheros .xlsx)}: indica la última columna (\textbf{2}, por defecto).
\end{enumerate}

Para distinguir entre los diferentes tipos de archivo, utilizaremos el comando \textit{strsplit} con el fin de 
separar el nombre del archivo de su extensión. Por otro lado, mediante el comando \textbf{unlist} convertimos la lista obtenida a vector.
Ejemplo:
<<>>=
aux = unlist(strsplit("fichero_entrada.txt","[.]"));
aux;
@

Una vez obtenida la extensión, mediante la función \textbf{switch} realizaremos la lectura de archivo, en función de su extensión. 
Para los archivos \textit{.json} y \textit{.xlsx} importaremos las librerías necesarias para su lectura.
\newpage
Código:
<<results=hide>>=
leer.archivo <- function(nombre, header = FALSE, sep = "", dec=".", skipNul=FALSE, 
				to.data.frame=TRUE, sheet=1,startRow=1,endCol=2){
	aux <- unlist(strsplit(nombre,"[.]"))
	switch(aux[length(aux)],
		"txt"={
			read.table(nombre,header=header, sep=sep, dec=dec, 
			skipNul=skipNul)
		},
		"csv"={
			read.csv(nombre,header=header, sep=sep, dec=dec, 
			skipNul=skipNul)
		},
		"json"={
			if(!require(rjson)){
				install.packages("rjson")
				require(rjson)
			}
			na.omit(as.data.frame(do.call(rbind,fromJSON(file=nombre))))
		},
		"sav"={
			require(foreign)
			read.spss(nombre,to.data.frame=to.data.frame)
		},
		"xlsx"={
			if(!require(XLConnect)){
				install.packages("XLConnect")
				require(XLConnect)
			}
			readWorksheetFromFile(nombre,sheet=sheet,startRow=startRow,
			endCol=endCol)
		}
	)
}
@
\newpage
\hfil \textbf{Ejemplo de ejecución con el fichero \textit{satelites.txt}}: \par
<<>>=
satelites <- leer.archivo("satelites.txt", T)
satelites
@
\hfil \textbf{Ejemplo de ejecución con el fichero \textit{datosDecontaminacion.json}} \par
<<results=hide>>=
datos_contaminacion <- leer.archivo("datos_de_contaminacion.json")
nrow(datos_contaminacion)
@

Dado el elevado número de filas obtenidas, vamos a utilizar el paquete \textit{dplyr} para mostrar un sobconjunto del data frame. Esta librería permite realizar consultas al dataframe,
similar a una consulta \texttt{SQL}\footnote{\url{https://rsanchezs.gitbooks.io/rprogramming/content/chapter9/dplyr.html}}. Esta librería proporciona los siguientes comandos para realizar
consultas sobre un data frame:
\begin{itemize}
	\item \textbf{select}: permite seleccionar un conjunto de columnas.
	\item \textbf{filter}: devuelve un conjunto de filas que cumplan una condición dada.
	\item \textbf{arrange}: permite reordenar las filas de un data frame.
	\item \textbf{rename}: permite renombrar variables en un data frame.
	\item \textbf{mutate}: permite añadir nuevas columnas o modificar columnas existentes.
	\item \textbf{head}: para obtener las primeras n filas.
	\item \textbf{summarise}: para calcular resúmenes estadísticos.
    \item \textbf{pipe}: se emplea para concatenar varias acciones.
\end{itemize}
\newpage
Si queremos obtener las 10 primeras filas del data frame anterior:
<<>>=
library(dplyr)
#pipe = %>%
#Equivalente a SELECT(fecha_medicion, tipo_contaminante, 
#contaminante, porcentaje) * FROM datos_contaminacion LIMIT 10
datos_contaminacion %>% select(fecha_medicion, tipo_contaminante, 
contaminante, porcentaje) %>% head(10)
@
\hfil \textbf{Ejemplo de ejecución con el fichero \textit{satelites.csv}} \par
<<>>=
satelites_csv <- leer.archivo("satelites.csv", T, ",")
satelites_csv
@
\newpage
\hfil \textbf{Ejemplo de ejecucion con el fichero \textit{cardata.sav}} \par
<<>>=
cardata <- leer.archivo("cardata.sav")
#Equivalente a SELECT(mpg, cylinders, accel, weight) FROM cardata
#LIMIT 10
cardata %>% select(mpg, cylinders, accel, weight) %>% head(10)
@
\hfil \textbf{Ejemplo de ejecucion con el fichero \textit{iris.xslx}}
<<>>=
#Fila de inicio: 1
#Numero de columnas: 6
iris <- leer.archivo("iris.xlsx", startRow = 1, endCol = 6)
#Equivalente a SELECT * FROM iris LIMIT 10
iris %>% head(10)
@

\subsection{Media aritmética}
Para realizar el cálculo de la media aritmética emplearemos una función que sumará recursivamente los elementos de la columna, hasta que
la longitud de la lista sea 1 (condición de parada), dividiendo finalmente la suma resultante entre el número total de elementos.
\newpage
Ejemplo:
<<results=hide>>=
## Media recursiva
# 
media.recursiva <- function(vector,n=0,sum=0){
	if(length(vector)==1){
		(sum+as.numeric(vector[1]))/(n+1)
	} else{
		media.recursiva(vector[2:length(vector)],n+1,sum+as.numeric(vector[1]))
	}
}
@
<<echo=false>>=
paste("Media de radios de satelites.txt: ",media.recursiva(satelites$radio))
paste("Media de radios de satelites.csv: ", media.recursiva(satelites_csv$radio))
paste("Media de mpg de cardata.sav: ", media.recursiva(na.omit(cardata$mpg)))
paste("Media de las longitudes de pétalo de iris.xslx: ", media.recursiva(iris$PetalLengthCm))
@

Por otro lado, si queremos calcular la media agrupada en clases, utlizaremos la librería \textit{dplyr}.

\hfil \textbf{Para calcular la aceleración en función de la marca de automóvil en \textit{cardata.sav}}: \par
<<>>=
library(dplyr)
#Eliminamos posibles filas a NA
#Equivalente a:
#SELECT mean(accel) FROM cardata GROUP_BY(make)
cardata %>% group_by(cardata$make) %>% summarise(aceleracion = mean(na.omit(cardata$accel)))
@
\newpage
\hfil \textbf{Para calcular la longitud de pétalo en función de la especie en \textit{iris.xlsx}}: \par
<<>>=
#Equivalente a:
#SELECT PetalLengthCm FROM iris GROUP_BY "Species"
iris %>% group_by(Species) %>% summarise(longitudPetalo = mean(PetalLengthCm))
@

Dado el elevado número de filas que presenta el fichero \textit{.json}, se produce un desbordamiento de la pila tras realizar la llamada recursiva.
Como consecuencia, emplearemos la función \textit{dplyr} para el cálculo de la media.

\textbf{Para calcular los niveles medios de concentracion por contaminante en función del tipo de contaminante en \textit{datosDecontaminacion.json}}:

<<>>=
#Mediante el comando MUTATE creamos una nueva columna
datos_contaminacion = datos_contaminacion %>% 
mutate(aux=unlist(datos_contaminacion$contaminante))
datos_contaminacion = datos_contaminacion %>% 
mutate(aux_num=as.numeric(datos_contaminacion$concentracion))
datos_contaminacion %>% group_by(aux) %>% 
summarise(media_concentracion=mean(na.omit(aux_num)))
@
\newpage
\subsection{Moda, Frecuencia Absoluta y Frecuencia Absoluta Acumulada}
Para realizar el cálculo de la Moda, creamos una función que obtenga la mayor frecuencia absoluta
<<results=hide>>=
## Moda
#
moda <- function(vector){
	aux=freq.absoluta(vector)
	moda=aux[which.max(aux$fi), ]$valor
	data.frame(moda)
}
@

Para calcular la frecuencia absoluta, crearemos una función recursiva. Para ello, utilizaremos la función \textit{match} que permitirá analizar las apariciones de un elemento
en una lista, devolviendo su posición. Por otro lado, una vez obtenida la frecuencia absoluta, mediante la función \textit{freq.absoluta.acumulada} vamos sumando de forma progresiva
los valores de cada columna.
<<results=hide>>=
## Frecuencia absoluta
#
freq.absoluta <- function(original,fi=NA,valor=NA){
	#Analizamos en primer lugar la primera aparicion
	#de nuestro primer elemento en la lista de valores
	#(incialmente a NA)
	num=match(original[1],valor)

	#Como condicion de parada, comprobamos si la lista de
	#elementos tiene longitud 1
	if(length(original)==1){
		if(is.na(num)){
			valor=c(valor,original[1])
			fi=c(fi,1)
		} else{
			fi[num]=fi[num]+1
		}
		valor=valor[2:length(valor)]
		fi=fi[2:length(fi)]
		aux=data.frame(valor,fi)
		aux[order(aux$valor),]
	} else{
		if(is.na(num)){
			valor=c(valor,original[1])
			fi=c(fi,1)
		} else{
			fi[num]=fi[num]+1
		}
		freq.absoluta(original[2:length(original)],fi,valor)
	}
}

## Frecuencia absoluta acumulada
#
freq.absoluta.acumulada <- function(vector){
	aux=freq.absoluta(vector)
	#Una vez obtenidos los valores de frecuencia
	#absoluta, mediante cumsum() vamos sumando
	#los valores de cada columna
	valor=aux$valor
	fai=cumsum(aux$fi)
	data.frame(valor,fai)
}
@

\hfil \textbf{Cálculo de moda, frecuencia absoluta y acumulada } \par
\hfil \textbf{para \textit{satelites.txt} y \textit{satelites.csv}}: \par
<<>>=
#Moda y frecuencias absolutas de satelites.txt
moda(satelites$radio)
freq.absoluta(satelites$radio)
freq.absoluta.acumulada(satelites$radio)

#Moda y frecuencias absolutas de satelites.csv
moda(satelites_csv$radio)
freq.absoluta(satelites_csv$radio)
freq.absoluta.acumulada(satelites_csv$radio)
@

\hfil \textbf{Cálculo de moda, frecuencia absoluta y acumulada }\par
\hfil \textbf{para los valores mpg de \textit{cardata.sav}} \par
<<>>=
moda(na.omit(cardata$mpg))
#Debido a la elevado numero de valores, vamos a mostrar los 10 primeros datos con dplyr
freq.absoluta(na.omit(cardata$mpg)) %>% head(10)
freq.absoluta.acumulada(na.omit(cardata$mpg)) %>% head(10)
@

De forma adicional, podemos también calcular tanto la moda como las frecuencias absolutas agrupadas en clases, mediante \textit{dplyr}. Dicha librería dispone de la función \textbf{do}, 
la cual permite ejecutar cualquier función sobre una o varias columnas de nuestro dataframe. Veamos un ejemplo:
\textbf{Cálculo de la moda, frecuencias abosluta y acumulada de longitud de pétalo en función de la especie de planta en \textit{iris.xslx}: }
<<>>=
freq.absoluta(iris$Species)
freq.absoluta.acumulada(iris$Species)
#Equivalente a:
#SELECT freq.absoluta(iris$PetalLengthCm) FROM iris GROUP_BY "Species"
iris %>% group_by(Species) %>% do(freq.absoluta(iris$PetalLengthCm)) %>% head(5)
@

Al igual que en la media, el fichero \textit{datosDecontaminacion.json} acaba desbordando lo pila debido al elevado número de filas. Por ello, utilizaremos una funcion iterativa:
<<results=hide>>=
#Funcion iterativa para el calculo de la frecuencia absoluta
freq.absoluta.iterativa <- function(original,fi=NA,valor=NA){
	
	for (i in 1:length(original)){
		num=match(original[i],valor)

		if(is.na(num)){
			valor=c(valor,original[i])
			fi=c(fi,1)
		} else{
			fi[num]=fi[num]+1
		}
	}
	#Mediante el comando unlist, nos aseguramos que los elementos
	#de la columna valor no sean de tipo lista	
	valor=unlist(valor[2:length(valor)])
	fi=fi[2:length(fi)]
	aux=data.frame(valor,fi)
	aux[order(aux$valor),]
}

## Frecuencia absoluta acumulada iterativa
#
freq.absoluta.acumulada.iterativa <- function(vector){
	aux=freq.absoluta.iterativa(vector)
	#Una vez obtenidos los valores de frecuencia
	#absoluta, mediante cumsum() vamos sumando
	#los valores de cada columna
	valor=aux$valor
	fai=cumsum(aux$fi)
	data.frame(valor,fai)
}
@
\newpage
Veamos un ejemplo para el \textbf{cálculo de las frecuencias y moda en \textit{datosDecontaminacion.json}: }
<<>>=
moda.iterativa(datos_contaminacion$contaminante)
freq.absoluta.iterativa(datos_contaminacion$contaminante)
freq.absoluta.acumulada.iterativa(datos_contaminacion$contaminante)
@

\subsection{Frecuencia relativa y frecuencia relativa acumulada}
Para realizar el cálculo de la frecuencia relativa, creamos una función que obtenga todas las frecuencias absolutas para, a continuación, dividirlas entre el número total de elementos.
Una vez obtenidos los valores de frecuencia relativa, mediante la función \textit{freq.relativa.acumulada} vamos sumando progresivamente los valores de \begin{equation} f_i \end{equation}:
<<results=hide>>=
## Frecuencia relativa
#
freq.relativa <- function(vector){
	aux=freq.absoluta(vector)
	#Una vez obtenidas las Frecuencias
	#absolutas dividimos cada valor entre
	#el numero total de elementos: sum(aux$fi)
	valor=aux$valor
	fri=aux$fi/sum(aux$fi)
	data.frame(valor,fri)
}

## Frecuencia relativa acumulada
#
freq.relativa.acumulada <- function(vector){
	aux=freq.relativa(vector)
	#Una vez obtenidos los valores de frecuencia
	#relativa, mediante cumsum() vamos sumando
	#los valores de cada columna
	valor=aux$valor
	frai=cumsum(aux$fri)
	data.frame(valor,frai)
}
@
Ejemplos de cálculo de frecuencias relativas:
<<>>=
#satelites.txt
freq.relativa(satelites$radio)
freq.relativa.acumulada(satelites$radio)

#satelites.csv
freq.relativa(satelites_csv$radio)
freq.relativa.acumulada(satelites_csv$radio)

#cardata.sav
freq.relativa(na.omit(cardata$mpg)) %>% head(10)
freq.relativa.acumulada(na.omit(cardata$mpg)) %>% head(10)

#iris.xlsx
freq.relativa(iris$Species)
freq.relativa.acumulada(iris$Species)
@

Para el fichero \textit{datosDecontaminacion.json} crearemos una función que llame a la función para el cálculo iterativo de la frecuencia abosluta :
<<>>=
freq.relativa.iterativa(datos_contaminacion$contaminante)
freq.relativa.iterativa.acumulada(datos_contaminacion$contaminante)
@
\newpage
\subsection{Varianza y Desviación Típica}

Para el calculo de la Varianza utilizaremos un función recursiva que calcule el sumatorio de las diferencias entre cada valor y la media. Como condición de parada, cuando el vector tenga longitud 1
dividimos el sumatorio entre el número total de elementos \textit{n}. Por otro lado, para el cálculo de la Desviación Típica aplicamos la raíz cuadrada sobre la Varianza.
<<results=hide>>=
## Varianza
#
varianza <- function(vector, n = 0, suma = 0, media = media.recursiva(vector)){
    if(length(vector) == 1){
        suma = suma + (vector[1]-media)^2
        n = n + 1
        suma/n
    }
    else{
        suma = suma + (vector[1]-media)^2
        n = n + 1
        varianza(vector[2:length(vector)], n, suma, media)
    }
}

## Desviacion tipica
#
desviacion.tipica <- function(vector){
	sqrt(varianza(vector))
}
@

Ejemplo de cálculo de Varianza y Desviación Típica:
<<>>=
#satelites.txt
varianza(satelites$radio)
desviacion.tipica(satelites$radio)

#satelites_csv
varianza(satelites_csv$radio)
desviacion.tipica(satelites_csv$radio)

#cardata.sav
varianza(na.omit(cardata$mpg))
desviacion.tipica(na.omit(cardata$mpg))

#iris.xlsx
varianza(iris$PetalLengthCm)
desviacion.tipica(iris$PetalLengthCm)
@

Para el fichero \textit{datosDecontaminacion.json} crearemos una función iterativa para el cálculo de la Varianza:
<<results=hide>>=
## Varianza iterativa
#
varianza.iterativa <- function(vector, suma = 0, media = media.iterativa(vector)){
    
	for(i in 1:length(vector)){
		suma = suma + (as.numeric(vector[i])-media)^2
	}
	suma/length(vector)
}
@
Ejemplos de ejecución:
<<>>=
varianza.iterativa(datos_contaminacion$aux_num)
desviacion.tipica.iterativa(datos_contaminacion$aux_num)
@

Para el fichero \textit{datosDecontaminacion.json} crearemos una función iterativa para el cálculo de la Varianza:
<<results=hide>>=
## Varianza iterativa
#
varianza.iterativa <- function(vector, suma = 0, media = media.iterativa(vector)){
    
	for(i in 1:length(vector)){
		suma = suma + (as.numeric(vector[i])-media)^2
	}
	suma/length(vector)
}
@
Ejemplos de ejecución:
<<>>=
#Eliminamos filas con cadenas vacias
datos_contaminacion <- datos_contaminacion[datos_contaminacion$concentracion != "" & datos_contaminacion$porcentaje != "",]
varianza.iterativa(datos_contaminacion$aux_num)
desviacion.tipica.iterativa(datos_contaminacion$aux_num)
@

\subsection{Mediana}
Para el cálculo de la mediana utilizaremos una función que comprobará inicialmente la longitud del vector de entrada:
\begin{itemize}
	\item Si el número de elementos es \textbf{impar}, la mediana es el elemento situado en la mitad del vector.
	\item Si el número de elementos es \textbf{par}, la mediana es la media resultante entre los dos elementos situados a la mitad del vector.
\end{itemize}
<<results=hide>>=
#Calculo de la mediana
#Funcion para comprobar si un numero es impar
is.odd <- function(x) x %% 2 != 0

mediana <- function(vector) {
    if(is.odd(length(vector))) #impar
    {
        as.numeric(vector[(length(vector)+1)/2])
    }else{ #par
        (as.numeric(vector[(length(vector))/2]) + 
		as.numeric(vector[((length(vector))/2)+1]))/2
    }
}
@
Ejemplos de ejecución:
<<>>=
#satelites.txt
mediana(satelites$radio)

#satelites.csv
mediana(satelites_csv$radio)

#cardata.sav
mediana(cardata$mpg)

#iris.xlsx
mediana(iris$PetalLengthCm)

#datos_contaminacion.json
mediana(datos_contaminacion$porcentaje)
@
\newpage
\subsection{Medidas de dispersión: Cuartiles}
\textbf{IMPORTANTE: para realizar el cálculo de los cuartiles los elementos han de estar ordenados.}
Para realizar el cálculo de los cuartiles, crearemos la siguiente función\footnote{\url{https://www.universoformulas.com/estadistica/descriptiva/cuartiles/}}:
\begin{enumerate}
	\item Para calcular el primer cuartil, calculamos la siguiente expresión \begin{equation} \frac{N+1}{4} \end{equation}
		\begin{enumerate}
			\item Si no contiene parte decimal el primer cuartil será \begin{equation} x_\frac{N+1}{4} \end{equation}
			\item Si contiene parte decimal el primer cuartil será \begin{equation} x_i + d\times(x_i+1 - x_i) \end{equation} donde \textit{i} es la parte entera y \textit{d} la parte decimal
		\end{enumerate}
	\item Para calcular el segundo cuartil calculamos la mediana.
	\item Para calcular el tercer cuartil, calculamos la siguiente expresión \begin{equation} \frac{3\times(N+1)}{4} \end{equation}
		\begin{enumerate}
			\item Si no contiene parte decimal el primer cuartil será \begin{equation}  x_\frac{3\times(N+1)}{4} \end{equation}
			\item Si contiene parte decimal el primer cuartil será \begin{equation} x_i + d\times(x_i+1 - x_i) \end{equation} donde \textit{i} es la parte entera y \textit{d} la parte decimal
		\end{enumerate}
\end{enumerate}

<<results=hide>>=
#Para el calculo de cuartiles, empleamos el algoritmo de Freund and Perles
#1er quartil: (n+3)/4
#3er quartil: (3*n+1)/4
quartiles <- function(vector) {
	#El vector ha de estar ordenado
	vector <- sort(vector)
    q1 <- (length(vector) + 3)/4
    if(q1 %% 1 != 0)
    {
        cuartil1 <- vector[trunc(q1)] + (q1 %% 1)*(vector[trunc(q1)+1] 
		- vector[trunc(q1)])
    }
    else{
        
        cuartil1 <- vector[trunc(q1)]
    }

    q2 <- mediana(vector)

    q3 <- (3*length(vector) + 1)/4
    if(q3 %% 1 != 0)
    {
        cuartil3 <- vector[trunc(q3)] + (q3 %% 1)*(vector[trunc(q3)+1] 
		- vector[trunc(q3)])
    }
    else{
        
        cuartil3 <- vector[trunc(q3)]
    }
    print(c(cuartil1,q2,cuartil3))
}
@

Para calcular el percentil 54, utilizaremos la función \textit{quantile}:
<<>>=
#satelites.txt
quartiles(satelites$radio)
quantile(satelites$radio, probs=0.54)

#satelites.csv
quartiles(satelites_csv$radio)
quantile(satelites_csv$radio, probs=0.54)

#cardata.sav
quartiles(cardata$mpg)

#iris.xlsx
quartiles(iris$PetalLengthCm)
quantile(iris$PetalLengthCm, probs=0.54)

#datos_contaminacion.json
quartiles(as.numeric(datos_contaminacion$concentracion))
#Eliminamos filas que contegan cadenas vacias
datos_contaminacion <- datos_contaminacion[datos_contaminacion$concentracion != "" 
& datos_contaminacion$porcentaje != "",]
quantile(as.numeric(datos_contaminacion$concentracion), probs=0.54)
@
\newpage
\section{Anexo: lectura de ficheros .csv}
Antes de acabar, debemos mencionar ciertas pautas para leer ficheros \textit{.csv}. Debemos seguir una serie de reglas para generar el formato correcto:
\begin{itemize}
	\item Debe haber una coma y un espacio entre dato y dato.
	\item Los datos se pueden separar con otro elemento. Por ejemplo: sep = ".".
	\item Cada grupo de datos (instancia) va en una sola fila.
    \item Hay que introducir un \textit{enter} al final de cada fila.
	\item Los decimales se introducen con punto.
	\item En las variables tipo caracter no se puede dejar un espacio entre caracteres.
\end{itemize}

\end{document}